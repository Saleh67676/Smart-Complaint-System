
from openai import OpenAI
import numpy as np
import pandas as pd
from dotenv import load_dotenv
import os
import json
import pickle
import gradio as gr
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
from datetime import datetime

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# File paths and similarity thresholds
EMBEDDINGS_FILE = "embeddings.pkl"
DATA_FILE = "slou.csv"
MISSED_QUESTIONS_FILE = "missed_questions.xlsx"
HIGH_MATCH = 0.60
MEDIUM_MATCH = 0.35

def get_embedding(text):
    """Generate embedding vector for text using OpenAI API"""
    try:
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"Embedding error: {e}")
        return None

def load_data_and_embeddings():
    """Load dataset and embeddings, generate if not cached"""
    data = pd.read_csv(DATA_FILE)
    if Path(EMBEDDINGS_FILE).exists():
        with open(EMBEDDINGS_FILE, "rb") as f:
            data["embedding"] = pickle.load(f)
        print("Embeddings loaded")
    else:
        print("Generating embeddings...")
        data["embedding"] = data["problem"].apply(get_embedding)
        with open(EMBEDDINGS_FILE, "wb") as f:
            pickle.dump(data["embedding"].tolist(), f)
        print("Embeddings saved")
    return data

data = load_data_and_embeddings()

def find_best_match(query):
    """Find most similar problem in dataset using cosine similarity"""
    query_emb = get_embedding(query)
    if query_emb is None:
        return None, 0, None
    all_embs = np.vstack(data["embedding"].tolist())
    sims = cosine_similarity([query_emb], all_embs)[0]
    idx = int(np.argmax(sims))
    row = data.iloc[idx]
    return row, float(sims[idx]), row.get("department", "Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø®ØªØµ")

def is_problem_or_question(message):
    """Check if message is a real problem/question or just a greeting"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """Classify if this is a real problem/question or just a greeting.

"problem": Real problem with details OR clear question
- "Ù…Ø§ Ø£Ù‚Ø¯Ø± Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¨ÙˆØ§Ø¨Ø©"
- "Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø© Ø¨Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"
- "Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø·ÙŠØ¡"

"general": Greeting or vague statement WITHOUT details
- "Ù…Ø±Ø­Ø¨Ø§", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…"
- "Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø©" (alone, no details)
- "Ø³Ø§Ø¹Ø¯Ù†ÙŠ" (alone)

Respond with JSON: {"type": "problem"} or {"type": "general"}"""
                },
                {"role": "user", "content": message}
            ],
            response_format={"type": "json_object"}
        )
        result = json.loads(resp.choices[0].message.content)
        return result.get("type") == "problem"
    except Exception:
        return True

def format_solution(problem, solution_text):
    """Rewrite solution in clear and polite manner"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Rewrite the solution in a clear, polite, and concise manner. Do not add new information"},
                {"role": "user", "content": f"Ù…Ø´ÙƒÙ„ØªÙƒ Ù‡ÙŠ: {problem}\nØ§Ù„Ø­Ù„: {solution_text}"}
            ]
        )
        return resp.choices[0].message.content
    except Exception:
        return solution_text

def summarize_problem(context_list):
    """Combine multiple user messages into one clear problem summary"""
    try:
        details = "\n".join(f"- {c}" for c in context_list)
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Summarize the user's problem in one clear sentence that captures all the provided details."},
                {"role": "user", "content": f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:\n{details}"}
            ]
        )
        return resp.choices[0].message.content
    except Exception:
        return " ".join(context_list)

def ask_clarification(context_list, attempt):
    """Ask user for more details to better understand their problem"""
    try:
        details = "\n".join(f"- {c}" for c in context_list)
        if attempt == 1:
            prompt = (
                f"The user has a problem:\n{details}\n\n"
                "Ask for ONE specific clarification. Ask only ONE clear question (for example:\n"
                "- What is the error message?\n"
                "- When did the issue start?\n"
                "- Did you try any solution?).\n\n"
                "Your response must be concise and polite."
            )
        else:
            prompt = (
                "The user has a problem and the solution is still unclear.\n\n"
                f"Here are the details provided so far:\n{details}\n\n"
                "Ask for additional clarification and reference what the user has already stated.\n"
                "Make sure your question is different from the previous one.\n"
                "Keep your response concise and polite."
            )
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a polite and helpful technical support assistant responsible for asking the user for clarifications."},
                {"role": "user", "content": prompt}
            ]
        )
        return resp.choices[0].message.content
    except Exception:
        return "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø£ÙƒØ«Ø±ØŸ Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø« Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ"

def log_missed_question(context_list, summary, department, score):
    """Save unresolved questions to Excel for review"""
    try:
        file_path = Path(MISSED_QUESTIONS_FILE)
        record = {
            "timestamp": datetime.utcnow().isoformat(),
            "original_text": "\n".join(context_list),
            "summary": summary,
            "department": department,
            "score": float(f"{score:.2f}")
        }
        if file_path.exists():
            df = pd.read_excel(file_path)
            df = pd.concat([df, pd.DataFrame([record])], ignore_index=True)
        else:
            df = pd.DataFrame([record])
        df.to_excel(file_path, index=False)
    except Exception as e:
        print(f"Error while logging missed question: {e}")

def is_out_of_scope(message):
    """Check if question is about external services outside IT support scope"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """Check if the message is about external services NOT related to university IT support.

OUT OF SCOPE (return true):
- YouTube, Netflix, streaming platforms
- Social media: Facebook, Twitter, Instagram, TikTok, Snapchat, WhatsApp (personal)
- Gaming platforms, personal apps
- Personal devices/accounts not related to university

IN SCOPE (return false):
- University network, internet, WiFi
- University email
- University portals, Blackboard, learning systems
- University computers, printers, labs

Respond with JSON: {"out_of_scope": true} or {"out_of_scope": false}"""
                },
                {"role": "user", "content": message}
            ],
            response_format={"type": "json_object"}
        )
        result = json.loads(resp.choices[0].message.content)
        return result.get("out_of_scope", False)
    except Exception:
        return False

def respond(message, history, session_state):
    """Main response logic handling different conversation states"""
    if session_state is None:
        session_state = {
            "context": [],
            "attempt": 0,
            "awaiting": False,
            "last_score": 0
        }

    # Handle follow-up responses when awaiting clarification
    if session_state["awaiting"]:
        session_state["context"].append(message)
        session_state["attempt"] += 1
        summary = summarize_problem(session_state["context"])
        print(f"Summary: {summary}")
        
        match, score, department = find_best_match(summary)
        print(f"Score (attempt {session_state['attempt']}): {score:.2%}")
        
        if match is None:
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", session_state

        session_state["last_score"] = score
        
        # High confidence - provide solution
        if score >= HIGH_MATCH:
            solution = format_solution(summary, match['solution'])
            session_state = {
                "context": [],
                "attempt": 0,
                "awaiting": False,
                "last_score": 0
            }
            return solution, session_state
        
        # Medium confidence - ask one more time
        if score >= 0.40 and session_state["attempt"] < 2:
            return ask_clarification(session_state["context"], 2), session_state
        
        # Low confidence - escalate to department
        details_summary = "\n".join([f"â€¢ {c}" for c in session_state["context"]])
        try:
            log_missed_question(
                context_list=session_state["context"],
                summary=summary,
                department=department,
                score=score
            )
        except Exception as e:
            print(f"Failed to log missed question: {e}")
        
        response_text = f"""Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯ Ø­Ù„ Ù…Ø¨Ø§Ø´Ø± Ù„Ù…Ø´ÙƒÙ„ØªÙƒ.

ðŸ“‹ *Ù…Ù„Ø®Øµ Ù…Ø´ÙƒÙ„ØªÙƒ:*
{details_summary}

ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø´ÙƒÙˆØ§Ùƒ Ø¥Ù„Ù‰: *{department}*

Ø³ÙŠØªÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ùƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹. Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙÙ‡Ù…Ùƒ!"""
        
        session_state = {
            "context": [],
            "attempt": 0,
            "awaiting": False,
            "last_score": 0
        }
        return response_text, session_state

    # Check if message is just a greeting
    if not is_problem_or_question(message):
        return "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. Ø£Ø±Ø³Ù„ ØªÙØ§ØµÙŠÙ„ Ù…Ø´ÙƒÙ„ØªÙƒ Ø£Ùˆ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ³Ø£Ø­Ø§ÙˆÙ„ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ðŸ˜Š", session_state
    
    # Check if question is outside support scope
    if is_out_of_scope(message):
        print(f"âŒ Out of scope detected: {message}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ ØªØ®ØµØµÙŠ ÙˆÙ„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠÙ‡.", session_state
    
    # Search for solution in database
    match, score, department = find_best_match(message)
    print(f"Initial score: {score:.2%}")
    
    if match is None:
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", session_state
    
   # High confidence match - provide direct solution
    if score >= HIGH_MATCH:
        return format_solution(message, match['solution']), session_state
    
    # Medium confidence - ask for clarification
    if score >= MEDIUM_MATCH:
        session_state = {
            "context": [message],
            "attempt": 1,
            "awaiting": True,
            "last_score": score
        }
        return ask_clarification([message], 1), session_state
    
    # ==========================================
    # Low confidence (< 0.35) - Escalate directly
    # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¹Ù„Ù‰ Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù€ if Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    # ==========================================
    try:
        log_missed_question([message], message, department, score)
    except Exception as e:
        print(f"Error logging: {e}")

    return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø­Ù„ Ù…Ø´ÙƒÙ„ØªÙƒ Ù…Ø¨Ø§Ø´Ø±Ø©.\nØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ø®ØªØµ: *{department}*", session_state

# Gradio interface setup
with gr.Blocks(theme="soft") as demo:
    gr.Markdown("# ðŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ\nØ£Ø±Ø³Ù„ Ù…Ø´ÙƒÙ„ØªÙƒ Ø£Ùˆ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ³Ø£Ø³Ø§Ø¹Ø¯Ùƒ")
    
    chatbot = gr.Chatbot(type="messages", height=400)
    msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...", rtl=True)
    session = gr.State(None)
    
    def user_submit(message, history, session_state):
        message = message.strip()
        if not message:
            return "", history, session_state
        
        history.append({"role": "user", "content": message})
        reply, session_state = respond(message, history, session_state)
        history.append({"role": "assistant", "content": reply})
        
        return "", history, session_state
    
    def clear_chat():
        return [], None
    
    msg.submit(user_submit, [msg, chatbot, session], [msg, chatbot, session])
    
    gr.Button("ðŸ”„ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©").click(clear_chat, None, [chatbot, session])

demo.launch()
